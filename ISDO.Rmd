```{r Packages}
# Check for packages and install if missing
if(!"terra" %in% installed.packages()){install.packages("terra")}
if(!"raster" %in% installed.packages()){install.packages("raster")}
if(!"rgdal" %in% installed.packages()){install.packages("rgdal")}
if(!"foreach" %in% installed.packages()){install.packages("foreach")}
if(!"doFuture" %in% installed.packages()){install.packages("doFuture")}
if(!"future" %in% installed.packages()){install.packages("future")}
if(!"jsonlite" %in% installed.packages()){install.packages("jsonlite")}

library(terra)
library(raster)
#library(rgdal)
library(doFuture)
library(jsonlite)

#plan(multisession)
```

```{r Raster}
# Load GLAD alert raster

# tf <- tempfile(fileext = ".tif") #create a temporary file


#glad_raster <- raster('https://storage.googleapis.com/earthenginepartners-hansen/GLADalert/C2/current/alertDate23_070W_10S_060W_00N.tif')
glad_raster_file <- "C:\\Users\\georg\\OneDrive - UBC\\Disciplinas\\GEOS 503\\alertDate22_060W_10S_050W_00N_sample.tif"
glad_raster <- raster(glad_raster_file)

# Transform Glad to binary (0s and 1s)
#glad_flat <- glad_raster/glad_raster

# Individualize and identify (tag) deforestation spots
clumped_glad <- clump(glad_flat)
f_clumped_glad <- freq(clumped_glad, useNA = 'no', progress = 'text')
f_clumped_glad <- as.data.frame(f_clumped_glad)

# make a new raster to be sieved
sieved_glad <- clumped_glad
# assign NA to all clumps whose IDs are found in excludeID (lass than 16 pixels together)
excludeID <- f_clumped_glad$value[which(f_clumped_glad$count <= 16)] #16 pixels = 1.44 hectare
sieved_glad[clumped_glad %in% excludeID] <- NA

writeRaster(sieved_glad, 's_glad.tif', progress='text', overwrite=TRUE)


```


```{r}
#Load country boundaries

json_file <- 'https://datahub.io/core/geo-countries/datapackage.json'
json_data <- fromJSON(paste(readLines(json_file), collapse=""))

# get list of all resources:
print(json_data$resources$name)

# print all tabular data(if exists any)
for(i in 1:length(json_data$resources$datahub$type)){
  if(json_data$resources$datahub$type[i]=='derived/csv'){
    path_to_file = json_data$resources$path[i]
    data <- read.csv(url(path_to_file))
    print(data)
  }
}
```



```{r csv}
#Find starting and last(end) dates of deforestation

sieved_matrix <- as.matrix(sieved_glad)
glad_matrix <- as.matrix(glad_raster)
start_end_dates <- data.frame(id=as.character(NA), start=as.POSIXct.Date(NA), end=as.POSIXct.Date(NA))#, speed=as.numeric(NA))

for (i in 1:length(fsg[,1])) {
  start_end_dates[i,] <- c(fsg[i,1], 
              strftime(as.Date(min(glad_matrix[which(sieved_matrix[]==fsg[i,1])]),origin="2022-01-01"), format = "%Y-%m-%d"), 
              strftime(as.Date(max(glad_matrix[which(sieved_matrix[]==fsg[i,1])]),origin="2022-01-01"), format = "%Y-%m-%d")
  )
  print(paste(i, 'from',length(fsg[,1]),'at', Sys.time()))
}
write.csv(start_end_dates, "startend.csv")


#Option to run in parallel 

#library(doFuture)
#library(doParallel)

cl <- makeCluster(6)
registerDoParallel(cl)

start_end_dates <- foreach(i=1:length(fsg[,1]), .combine=rbind, .verbose = TRUE) %dopar% {
  print(paste(i, 'from',length(fsg[,1]),'at', Sys.time()))
  return(c(fsg[i,1], 
    strftime(as.Date(min(glad_matrix[which(sieved_matrix[]==fsg[i,1])]),origin="2022-01-01"), format = "%Y-%m-%d"), 
    strftime(as.Date(max(glad_matrix[which(sieved_matrix[]==fsg[i,1])]),origin="2022-01-01"), format = "%Y-%m-%d")
   )
)
}
stopCluster(cl)
start_end_dates <- as.data.frame(start_end_dates)
write.csv(start_end_dates, "startend.csv")

```



```{r Vector}
# Raster to vetor convertion

fsg <- freq(sieved_glad)


# poligonos <- rasterToPoints(sieved_glad, fun=function(x) {x == 9575}, dissolve = TRUE)
pontos <- rasterToPoints(sieved_glad, fun=function(x) {x == 9575}, dissolve = TRUE)
agora <- sf::st_polygon(list(as.matrix(pontos[c(chull(pontos), chull(pontos)[1]),])))



# Generate spatial vector of polygons
poligonos_individualizados <- lapply(poligonos@polygons, function(poligono) {
  return(Polygon(poligono@Polygons[[1]]@coords))
})

# Armazenar os polígonos individualizados em um objeto de camada de polígono
poligonos_camada <- SpatialPolygons(poligonos_individualizados)

plot(poligonos_camada)
```
